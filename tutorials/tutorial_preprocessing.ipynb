{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating your submission_config file\n",
    "\n",
    "This file will tell the preprocessing pipeline how each submission should be processed. I will show two examples of possible submissions and explain how different parameters affect the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sub_set = \"/path/to/submissions/\"\n",
    "\n",
    "submission1_path = os.path.join(path_to_sub_set, \"path/to/submission1\")\n",
    "submission2_path = os.path.join(path_to_sub_set, \"path/to/submission2\")\n",
    "\n",
    "path_gt = \"/path/to/ground_truth/\"\n",
    "\n",
    "submission_config = {\n",
    "    \"gt\": {\n",
    "        \"name\": \"gt\",\n",
    "        \"path\": path_gt,\n",
    "        \"box_size\": 224,\n",
    "        \"pixel_size\": 1.073 * 2,\n",
    "        \"ref_align_fname\": \"1.mrc\",\n",
    "    },\n",
    "    0: {\n",
    "        \"name\": \"submission1\",\n",
    "        \"align\": 0,\n",
    "        \"box_size\": 144,\n",
    "        \"pixel_size\": 1.073 * 2,\n",
    "        \"path\": submission1_path,\n",
    "        \"populations_file\": \"path/to/populations_file1\",\n",
    "    },\n",
    "    1: {\n",
    "        \"name\": \"submission2\",\n",
    "        \"align\": 1,\n",
    "        \"box_size\": 288,\n",
    "        \"pixel_size\": 1.073,\n",
    "        \"path\": submission2_path,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission config\n",
    "with open(\"submission_config.json\", \"w\") as f:\n",
    "    json.dump(submission_config, f, indent=4)\n",
    "\n",
    "# load submission_config from json\n",
    "with open(\"submission_config.json\", \"r\") as f:\n",
    "    submission_config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you create your submission_config, simply grab a copy of the file \"config_preproc.yaml\" from the provided config_files, and change the path for the \"submission_config_file\" to the file we created in the previous cell. Also change the path for the output. The rest of the parameters you can leave untouched. Please see the publication \"Singer, A., & Yang, R. (2024). Alignment of density maps in Wasserstein distance. Biological Imaging, 4, e5\" for more details. Then simply run\n",
    "\n",
    "```bash\n",
    "cryo_challenge run_preprocessing --config /path/to/config_preproc.yaml\n",
    "```\n",
    "\n",
    "Note: make sure to activate your environment and have the package installed!\n",
    "\n",
    "You can run the following cell to visualize your volumes (more precisely, a projection of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_submissions = 2  # change this to however many submissions you preprocessed\n",
    "\n",
    "fig, ax = plt.subplots(2, 6, figsize=(20, 8))  # change values here too\n",
    "\n",
    "for i in range(n_submissions):\n",
    "    idx = np.random.randint(\n",
    "        0, 20\n",
    "    )  # doing random volumes to check that everything went fine\n",
    "\n",
    "    submission = torch.load(f\"/path/to/output/submission_{i}.pt\")\n",
    "    print(submission[\"volumes\"].shape, submission[\"id\"])\n",
    "    ax.flatten()[i].imshow(submission[\"volumes\"][idx].sum(axis=0))\n",
    "    ax.flatten()[i].set_title(submission[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryo-challenge-kernel",
   "language": "python",
   "name": "cryo-challenge-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
